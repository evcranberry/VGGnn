# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F6Wce8T1hesdxGA1TCOELTL5dCyW36iq
"""

from google.colab import drive
drive.mount('/content/drive')

!pip -qq install torchutils

import torch
import torchvision
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets
from torchvision import transforms as T

# Для чтения изображений с диска
from torchvision import io # input/output
import torchutils as tu
import numpy as np
import matplotlib.pyplot as plt

DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
print(DEVICE)

from torchvision.models import vgg19_bn, VGG19_BN_Weights
model = vgg19_bn(weights=VGG19_BN_Weights)

model

model.to(DEVICE)
prob_batch = torch.randn(4, 3, 224, 224, device=DEVICE)
tu.get_model_summary(model, prob_batch)

model.classifier[6]

model.classifier[6] = nn.Linear(4096, 4)

!unzip -o '/content/drive/MyDrive/coffee-beans-clf.zip' -d '/content/drive/MyDrive/'

for param in model.parameters():
    print(param.requires_grad)

for param in model.parameters():
    param.requires_grad = False

model.classifier[6].weight.requires_grad = True
model.classifier[6].bias.requires_grad = True

trnsfrms = T.Compose(
    [
        T.Resize((224, 224)),
        T.ToTensor()
    ]
)

train_dataset = torchvision.datasets.ImageFolder('/content/drive/MyDrive/coffee-beans/train', transform=trnsfrms)
test_dataset = torchvision.datasets.ImageFolder('/content/drive/MyDrive/coffee-beans/test', transform=trnsfrms)

train_dataset.class_to_idx

coffee_types = {0: 'Dark', 1: 'Green', 2: 'Light', 3: 'Medium'}

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)

optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)
criterion = torch.nn.CrossEntropyLoss()

def fit(
        model: torch.nn.Module,
        n_epochs: int,
        optimizer: torch.optim.Optimizer,
        train_loader: DataLoader,
        valid_loader: DataLoader,
        history = None,
        criterion = nn.CrossEntropyLoss()
        ) -> tuple[list, ...]:
    """Function to fit model

    Returns:
        train_losses: list of train losses per epoch
        valid_losses: list of valid losses per epoch
        train_acc: list of train accuracy per epoch
        valid_acc: list of valid accuracy per epoch
    """
    history = history or {
        'train_accs' : [],
        'valid_accs' : [],
        'train_losses' : [],
        'valid_losses' : []
    }

    for epoch in range(n_epochs):

        print(f'{"-"*13} Epoch {epoch} {"-"*13}')

        model.train()
        train_accs = []
        train_losses = []

        for images, labels in train_loader:
            images = images.to(DEVICE)
            labels = labels.to(DEVICE)

            y_pred = model(images)

            loss = criterion(y_pred, labels)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            train_losses.append(loss.item())
            train_accs.append((y_pred.argmax(axis=1) == labels).cpu().numpy().mean())

        history['train_losses'].append(np.mean(train_losses))
        history['train_accs'].append(np.mean(train_accs))

        model.eval()
        val_accs = []
        val_losses = []

        for images, labels in valid_loader:
            images = images.to(DEVICE)
            labels = labels.to(DEVICE)
            with torch.no_grad():
                y_pred = model(images)

            loss = criterion(y_pred, labels)

            val_accs.append((y_pred.cpu().argmax(axis=1) == labels.cpu()).numpy().mean())
            val_losses.append(loss.item())

        history['valid_losses'].append(np.mean(val_losses))
        history['valid_accs'].append(np.mean(val_accs))

        print(f'train: accuracy {history["train_accs"][-1]:.4f}, loss {history["train_losses"][-1]:.4f}\nvalid: accuracy {history["valid_accs"][-1]:.4f}, losses {history["valid_losses"][-1]:.4f}')
    return history

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = model.to(device)

for inputs, labels in train_loader:
    inputs = inputs.to(device)
    labels = labels.to(device)

hist = fit(model=model, optimizer=optimizer, train_loader=train_loader, valid_loader=test_loader, n_epochs=15)

fig, ax = plt.subplots(4, 8, figsize=(20, 12))
ax = ax.flatten() # переводим в одномерный массив
test_batch = next(iter(test_loader))
test_samples, test_targets = test_batch
test_samples = test_samples.to(DEVICE)
for i, plot in enumerate(ax):
    label_index = test_targets[i].item()  # Получаем индекс метки из тестового набора
    y_pred = torch.argmax(model(test_samples[i].unsqueeze(0)))
    y_pred = y_pred.cpu().detach().numpy()
    color = 'r' if y_pred != label_index else 'b'
    plot.set_title(f'  Label: {label_index} - {train_loader.dataset.classes[label_index]}\n'
                   f'Predict: {y_pred} - {train_loader.dataset.classes[y_pred]}', color=color)
    if test_samples[i].shape[0] == 3:  # Если 3 канала (RGB)
        img = test_samples[i].permute(1, 2, 0)  # Транспонируем в (высота, ширина, каналы)
        #img = (img + 1) / 2  # Переводим в диапазон [0, 1]
        #img = img * 255      # Переводим в диапазон [0, 255]
        #img = img.int()
    plot.imshow(img.cpu())#plot.matshow(test_samples[i][0, :, :].cpu().detach().numpy(), cmap='gray')
    plot.axis('off')

train_accs = np.array(hist['train_accs'])
valid_accs = np.array(hist['valid_accs'])

train_loss = np.array(hist['train_losses'])
valid_loss = np.array(hist['valid_losses'])

train_accs.min()

fig, ax = plt.subplots(1, 2, figsize=(14, 4))
ax[0].plot(hist['train_losses'], label='train loss')
ax[0].plot(hist['valid_losses'], label='valid loss')
ax[0].set_title(f'Loss on epoch {len(hist["train_losses"])}')
ax[0].set_ylim((0, max(hist['train_losses'] + hist['valid_losses'])+.1))
ax[0].legend()

ax[1].plot(train_accs, label='train acc')
ax[1].plot(valid_accs, label='valid acc')
ax[1].set_ylim((train_accs.min()-0.1), 1)
ax[1].set_title(f'Accuracy on epoch {len(hist["train_losses"])}')
ax[1].legend()

plt.show()

from PIL import Image

def get_prediction(path: str) -> int:
    # Открываем изображение с помощью PIL
    img = Image.open(path).convert("RGB")  # Конвертируем в RGB если это необходимо
    img = trnsfrms(img)  # Применяем трансформации
    plt.imshow(torch.permute(img, (1, 2, 0)))
    with torch.inference_mode():
        output = model(img.unsqueeze(0).to(DEVICE))  # Получаем вывод модели
        pred_class = torch.argmax(output, dim=1).item()  # Получаем индекс класса с наибольшей вероятностью
    return coffee_types[pred_class]

print(get_prediction('/content/drive/MyDrive/Unknown'))

coffee_types

torch.save(model.state_dict(), '/content/drive/MyDrive/weights.pt')

